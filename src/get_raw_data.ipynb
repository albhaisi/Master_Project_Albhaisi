{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Read global config file, all parameters are supposed to be defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:\n",
      "cross_fold:\n",
      "- LOOCV_1\n",
      "- LOOCV_2\n",
      "- LOOCV_3\n",
      "- LOOCV_4\n",
      "- LOOCV_5\n",
      "detection_candidate_fusion:\n",
      "  resultpath: /detection_eval/pod/raw\n",
      "detection_config: detection_itsc_2022\n",
      "detection_system:\n",
      "  CenterPoint_Pillar_02: /detection_eval/CenterPoint/Pillar02\n",
      "  CenterPoint_Voxel_0075: /detection_eval/CenterPoint/Voxel0075\n",
      "  CenterPoint_Voxel_01: /detection_eval/CenterPoint/Voxel01\n",
      "  PointPillar: /detection_eval/PointPillar\n",
      "init:\n",
      "  dataroot: dataroot\n",
      "  version: v1.0-trainval\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config_path = '/app/global_config/pod_data_prep_v0.yaml'\n",
    "with open(config_path, 'r') as stream:\n",
    "    configs = yaml.load(stream,  Loader=yaml.FullLoader)\n",
    "    \n",
    "print('Loaded config:')\n",
    "print(yaml.dump(configs))#  matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init nuscenes dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17284/3618586423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnuscenes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNuScenes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnusc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNuScenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataroot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/app/nuscenes/nuscenes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, dataroot, verbose, map_resolution)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scene'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_annotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_annotation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/nuscenes/nuscenes.py\u001b[0m in \u001b[0;36m__load_table__\u001b[0;34m(self, table_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;34m\"\"\" Loads a table. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  matplotlib inline\n",
    "from nuscenes import NuScenes\n",
    "\n",
    "nusc = NuScenes(version=configs['init']['version'], dataroot=configs['init']['dataroot'], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prediction boxes\n",
    "According to global config settings \n",
    "\n",
    "--> change to fold wise processing to avoid overloading memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load predicted boxes: CenterPoint_Pillar_02 LOOCV_1\n",
      "Load predicted boxes: CenterPoint_Pillar_02 LOOCV_2\n",
      "Load predicted boxes: CenterPoint_Pillar_02 LOOCV_3\n",
      "Load predicted boxes: CenterPoint_Pillar_02 LOOCV_4\n",
      "Load predicted boxes: CenterPoint_Pillar_02 LOOCV_5\n",
      "CenterPoint_Pillar_02: 34149 sample_token\n",
      "Load predicted boxes: CenterPoint_Voxel_01 LOOCV_1\n",
      "Load predicted boxes: CenterPoint_Voxel_01 LOOCV_2\n",
      "Load predicted boxes: CenterPoint_Voxel_01 LOOCV_3\n",
      "Load predicted boxes: CenterPoint_Voxel_01 LOOCV_4\n",
      "Load predicted boxes: CenterPoint_Voxel_01 LOOCV_5\n",
      "CenterPoint_Pillar_02: 34149 sample_token\n",
      "CenterPoint_Voxel_01: 34149 sample_token\n",
      "Load predicted boxes: CenterPoint_Voxel_0075 LOOCV_1\n",
      "Load predicted boxes: CenterPoint_Voxel_0075 LOOCV_2\n",
      "Load predicted boxes: CenterPoint_Voxel_0075 LOOCV_3\n",
      "Load predicted boxes: CenterPoint_Voxel_0075 LOOCV_4\n",
      "Load predicted boxes: CenterPoint_Voxel_0075 LOOCV_5\n",
      "CenterPoint_Pillar_02: 34149 sample_token\n",
      "CenterPoint_Voxel_01: 34149 sample_token\n",
      "CenterPoint_Voxel_0075: 34149 sample_token\n",
      "Load predicted boxes: PointPillar LOOCV_1\n",
      "Load predicted boxes: PointPillar LOOCV_2\n",
      "Load predicted boxes: PointPillar LOOCV_3\n",
      "Load predicted boxes: PointPillar LOOCV_4\n",
      "Load predicted boxes: PointPillar LOOCV_5\n",
      "CenterPoint_Pillar_02: 34149 sample_token\n",
      "CenterPoint_Voxel_01: 34149 sample_token\n",
      "CenterPoint_Voxel_0075: 34149 sample_token\n",
      "PointPillar: 34149 sample_token\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from nuscenes.eval.detection.data_classes import DetectionBox\n",
    "from nuscenes.eval.common.data_classes import EvalBoxes\n",
    "from nuscenes.eval.common.config import config_factory\n",
    "\n",
    "from nuscenes.utils.srs_utils import load_pred_boxes, load_gt_boxes\n",
    "cfg = config_factory(configs['detection_config'])\n",
    "\n",
    "\n",
    "\n",
    "def somethingelse():\n",
    "    return 0\n",
    "\n",
    "def something():\n",
    "    return 0\n",
    "\n",
    "mode = 'test'\n",
    "\n",
    "if mode == 'test':\n",
    "    something()\n",
    "elif mode == 'else':\n",
    "    somethingelse()\n",
    "\n",
    "def f(detector_path,folds):\n",
    "    pred_boxes = {}\n",
    "        \n",
    "    for detector,path in detector_path.items():\n",
    "        key = detector\n",
    "        pred_boxes[key] = EvalBoxes()\n",
    "        \n",
    "        for fold in folds:\n",
    "            print(f'Load predicted boxes: {detector} {fold}')\n",
    "\n",
    "            path_name = os.path.join(path,fold,'results_nusc.json')            \n",
    "            boxes = load_pred_boxes(nusc = nusc,\n",
    "                        cfg = cfg,\n",
    "                        result_path = path_name,\n",
    "                        box_cls = DetectionBox)\n",
    "            for sample_token in [s for s in boxes.sample_tokens]:\n",
    "                pred_boxes[key].add_boxes(sample_token,boxes[sample_token])\n",
    "        for k,v in pred_boxes.items():\n",
    "            print(f'{k}: {len(v.sample_tokens)} sample_token')\n",
    "\n",
    "    return pred_boxes\n",
    "\n",
    "pred_boxes = f(configs['detection_system'],configs['cross_fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_boxes: 34149 sample_token\n"
     ]
    }
   ],
   "source": [
    "gt_boxes = EvalBoxes()\n",
    "for fold in configs['cross_fold']:\n",
    "    boxes = load_gt_boxes(  nusc = nusc,\n",
    "                    cfg = cfg,\n",
    "                    eval_set = fold + '_val')\n",
    "    for sample_token in [s for s in boxes.sample_tokens]:\n",
    "        gt_boxes.add_boxes(sample_token,boxes[sample_token])\n",
    "\n",
    "print(f'gt_boxes: {len(gt_boxes.sample_tokens)} sample_token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions\n",
    "Return optional processparameter as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: CenterPoint_Pillar_02, v: EvalBoxes with 2978160 boxes across 34149 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519547/519547 [01:32<00:00, 5602.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/car/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210891/210891 [00:14<00:00, 14862.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/truck/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34476/34476 [00:01<00:00, 18052.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/bus/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111322/111322 [00:05<00:00, 19756.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/trailer/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208202/208202 [00:08<00:00, 24351.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/construction_vehicle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 534259/534259 [00:54<00:00, 9886.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/pedestrian/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273991/273991 [00:13<00:00, 20486.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/motorcycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 638838/638838 [00:33<00:00, 18909.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/bicycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334844/334844 [00:30<00:00, 11146.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/traffic_cone/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111790/111790 [00:23<00:00, 4665.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Pillar_02/barrier/results.json\n",
      "k: CenterPoint_Voxel_01, v: EvalBoxes with 2131440 boxes across 34149 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 493333/493333 [01:44<00:00, 4713.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/car/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165450/165450 [00:11<00:00, 14481.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/truck/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25326/25326 [00:01<00:00, 20312.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/bus/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66143/66143 [00:04<00:00, 15027.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/trailer/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93524/93524 [00:03<00:00, 23586.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/construction_vehicle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422645/422645 [00:46<00:00, 9086.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/pedestrian/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171683/171683 [00:06<00:00, 26525.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/motorcycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324178/324178 [00:12<00:00, 26220.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/bicycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259205/259205 [00:21<00:00, 12186.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/traffic_cone/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109953/109953 [00:22<00:00, 4957.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_01/barrier/results.json\n",
      "k: CenterPoint_Voxel_0075, v: EvalBoxes with 2015573 boxes across 34149 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464089/464089 [01:22<00:00, 5627.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/car/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165104/165104 [00:11<00:00, 14026.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/truck/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27234/27234 [00:01<00:00, 17873.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/bus/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64240/64240 [00:03<00:00, 18437.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/trailer/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88729/88729 [00:03<00:00, 25763.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/construction_vehicle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391382/391382 [00:35<00:00, 10957.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/pedestrian/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173553/173553 [00:04<00:00, 36225.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/motorcycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276891/276891 [00:09<00:00, 30720.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/bicycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257009/257009 [00:18<00:00, 13604.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/traffic_cone/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107342/107342 [00:18<00:00, 5904.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/CenterPoint_Voxel_0075/barrier/results.json\n",
      "k: PointPillar, v: EvalBoxes with 6327404 boxes across 34149 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1506214/1506214 [02:36<00:00, 9603.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/car/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 668380/668380 [00:39<00:00, 17095.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/truck/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137439/137439 [00:05<00:00, 23294.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/bus/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201045/201045 [00:08<00:00, 24229.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/trailer/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233897/233897 [00:08<00:00, 27938.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/construction_vehicle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1395445/1395445 [01:31<00:00, 15190.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/pedestrian/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219053/219053 [00:06<00:00, 33688.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/motorcycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329980/329980 [00:10<00:00, 32672.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/bicycle/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 966672/966672 [00:45<00:00, 21284.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/traffic_cone/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669279/669279 [00:46<00:00, 14277.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/detection_eval/pod/raw/PointPillar/barrier/results.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from typing import Callable\n",
    "from nuscenes.eval.common.utils import center_distance, scale_iou, yaw_diff, velocity_l2, attr_acc, cummean\n",
    "\n",
    "def accumulate(gt_boxes: EvalBoxes,\n",
    "               pred_boxes: EvalBoxes,\n",
    "               class_name: str = 'car',\n",
    "               dist_fcn: Callable = center_distance,\n",
    "               dist_th: float = 2.0,\n",
    "               verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Average Precision over predefined different recall thresholds for a single distance threshold.\n",
    "    The recall/conf thresholds and other raw metrics will be used in secondary metrics.\n",
    "    :param gt_boxes: Maps every sample_token to a list of its sample_annotations.\n",
    "    :param pred_boxes: Maps every sample_token to a list of its sample_results.\n",
    "    :param class_name: Class to compute AP on.\n",
    "    :param dist_fcn: Distance function used to match detections and ground truths.\n",
    "    :param dist_th: Distance threshold for a match.\n",
    "    :param verbose: If true, print debug messages.\n",
    "    :return: (average_prec, metrics). The average precision value and raw data for a number of metrics.\n",
    "    \"\"\"\n",
    "    # ---------------------------------------------\n",
    "    # Organize input and initialize accumulators.\n",
    "    # ---------------------------------------------\n",
    "\n",
    "    # Count the positives.\n",
    "    npos = len([1 for gt_box in gt_boxes.all if gt_box.detection_name == class_name])\n",
    "    #ego_dist = [gt_box.ego_dist for gt_box in gt_boxes.all if gt_box.detection_name == class_name])\n",
    "    if verbose:\n",
    "        print(\"Found {} GT of class {} out of {} total across {} samples.\".\n",
    "              format(npos, class_name, len(gt_boxes.all), len(gt_boxes.sample_tokens)))\n",
    "\n",
    "    # For missing classes in the GT, return a data structure corresponding to no predictions.\n",
    "    if npos == 0:\n",
    "        return None\n",
    "        # return DetectionMetricData.no_predictions()\n",
    "\n",
    "    # Organize the predictions in a single list.\n",
    "    pred_boxes_list = [box for box in pred_boxes.all if box.detection_name == class_name]\n",
    "    pred_confs = [box.detection_score for box in pred_boxes_list]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Found {} PRED of class {} out of {} total across {} samples.\".\n",
    "              format(len(pred_confs), class_name, len(pred_boxes.all), len(pred_boxes.sample_tokens)))\n",
    "\n",
    "    # Sort by confidence.\n",
    "    sortind = [i for (v, i) in sorted((v, i) for (i, v) in enumerate(pred_confs))][::-1]\n",
    "\n",
    "    # Do the actual matching.\n",
    "    tp = []  # Accumulator of true positives.\n",
    "    fp = []  # Accumulator of false positives.\n",
    "    fn = []  # Accumulator of false negatives.\n",
    "    conf = []  # Accumulator of confidences.\n",
    "    dist = []  # Accumulator of distances.\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Match and accumulate match data.\n",
    "    # ---------------------------------------------\n",
    "    match_data = pd.DataFrame()\n",
    "    taken = set()  # Initially no gt bounding box is matched.\n",
    "    for ind in tqdm(sortind):\n",
    "        pred_box = pred_boxes_list[ind]\n",
    "        min_dist = np.inf\n",
    "        match_gt_idx = None\n",
    "\n",
    "        for gt_idx, gt_box in enumerate(gt_boxes[pred_box.sample_token]):\n",
    "            # Find closest match among ground truth boxes\n",
    "            if gt_box.detection_name == class_name and not (pred_box.sample_token, gt_idx) in taken:\n",
    "                this_distance = dist_fcn(gt_box, pred_box)\n",
    "                if this_distance < min_dist:\n",
    "                    min_dist = this_distance\n",
    "                    match_gt_idx = gt_idx\n",
    "                    # add reference to closest annotation\n",
    "                    sample_annotation_token = gt_box.sample_annotation_token\n",
    "        # If the closest match is close enough according to threshold we have a match!\n",
    "        is_match = min_dist < dist_th\n",
    "\n",
    "        if is_match:\n",
    "            # No match. Mark this as a true positive.\n",
    "            taken.add((pred_box.sample_token, match_gt_idx))\n",
    "\n",
    "            tp.append(1)\n",
    "            fp.append(0)\n",
    "            fn.append(0)\n",
    "            conf.append(pred_box.detection_score)\n",
    "            dist.append(pred_box.ego_dist)\n",
    "\n",
    "            # add sample token as reference to gt\n",
    "            pred_box.sample_annotation_token = sample_annotation_token\n",
    "        else:\n",
    "            # No match. Mark this as a false positive.\n",
    "            tp.append(0)\n",
    "            fp.append(1)\n",
    "            fn.append(0)\n",
    "            conf.append(pred_box.detection_score)\n",
    "            dist.append(pred_box.ego_dist)\n",
    "            \n",
    "            # add sample token as reference to gt\n",
    "            pred_box.sample_annotation_token = None\n",
    "\n",
    "    # Add missed gt annotations as fn\n",
    "    for sample_token in gt_boxes.sample_tokens:\n",
    "        for gt_idx, gt_box in enumerate(gt_boxes[sample_token]):\n",
    "            if gt_box.detection_name == class_name and not (sample_token, gt_idx) in taken:\n",
    "                tp.append(0)\n",
    "                fp.append(0)\n",
    "                fn.append(1)\n",
    "                conf.append(-1)\n",
    "                dist.append(gt_box.ego_dist)\n",
    "                \n",
    "    return tp,fp,fn,conf,dist\n",
    "class_names =  [\"car\",\n",
    "                \"truck\",\n",
    "                \"bus\",\n",
    "                \"trailer\",\n",
    "                \"construction_vehicle\",\n",
    "                \"pedestrian\",\n",
    "                \"motorcycle\",\n",
    "                \"bicycle\",\n",
    "                \"traffic_cone\",\n",
    "                \"barrier\"]\n",
    "\n",
    "destination = configs['detection_candidate_fusion']['resultpath']\n",
    "for k,v in pred_boxes.items():\n",
    "    print(f'k: {k}, v: {v}')\n",
    "    for class_name in ['car','pedestrian']:# class_names: #\n",
    "        data = {}\n",
    "        data['tp'],data['fp'],data['fn'],data['score'],data['dist'] = accumulate( gt_boxes = gt_boxes, pred_boxes = v, class_name = class_name)\n",
    "\n",
    "        # safe results\n",
    "        directory = os.path.join(destination,k,class_name)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        result_path = os.path.join(directory,'results.json')\n",
    "        print(result_path)\n",
    "        with open(result_path, 'w') as f:\n",
    "            json.dump(data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
